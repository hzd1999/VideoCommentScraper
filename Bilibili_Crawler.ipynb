{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Eric He"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup \n",
    "from lxml import etree\n",
    "import json\n",
    "import csv,codecs\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Retrieving id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with column name 'title', 'id','link'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAid(url):   \n",
    "    ret = []\n",
    "    headers = { \n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'\n",
    "    } \n",
    "    try:\n",
    "        response = requests.get(url,headers=headers)\n",
    "\n",
    "        #将一段文档传入BeautifulSoup的构造方法,就能得到一个文档的对象, 可以传入一段字符串\n",
    "        soup = BeautifulSoup(response.text,'lxml')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    #Storing \n",
    "    titles = []\n",
    "    ids = []\n",
    "    links = []\n",
    "    items = soup.find(class_ = \"rank-list\").findAll(\"li\")\n",
    "    for x in items:\n",
    "        vid_title = x.find(class_ = \"info\").a.getText()\n",
    "        vid_link = x.find(\"a\")[\"href\"][2:]\n",
    "        vid_id = x[\"data-id\"]\n",
    "        titles.append(vid_title)\n",
    "        ids.append(vid_id)\n",
    "        links.append(vid_link)\n",
    "    l = list(zip(titles,ids,links))\n",
    "    df = pd.DataFrame(l,columns = ['title','id','link'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(s):\n",
    "    if \"回复\" in s:\n",
    "        k = s.index(\":\")\n",
    "        s = s[k+1:]\n",
    "    if s[0] == '\"':\n",
    "        s = s[1:]\n",
    "    if s[len(s)-1] == '\"':\n",
    "        s = s[:-1]\n",
    "    s = re.sub(\"\\n\",\"\",s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeUrls(pg,aid):\n",
    "    ret = []\n",
    "    for i in range(pg):\n",
    "        u = \"https://api.bilibili.com/x/v2/reply/main?jsonp=jsonp&next=\"+str(i)+\"&type=1&oid=\"+aid+\"&mode=3&plat=1&_=1627952418487\"\n",
    "        ret.append(u)\n",
    "    return ret\n",
    "# l = makeUrls(3,'291880951')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def getComments(df, num_vids):\n",
    "    f = codecs.open('bilibili_Comments.csv','w','utf_8_sig')\n",
    "    word_writer = csv.writer(f)\n",
    "    word_writer.writerow([\"comment\",\"video_title\",\"video_id\",\"video_link\"])\n",
    "    for i in range(num_vids):\n",
    "        aid = df.iloc[i].id\n",
    "        title = df.iloc[i].title\n",
    "        link = df.iloc[i].link\n",
    "        urls = makeUrls(1,aid) #add more pages if want more comments 1page = 80ish comments\n",
    "        for url in urls:\n",
    "            time.sleep(2)\n",
    "            headers = { \n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'\n",
    "            } \n",
    "            try:\n",
    "                response = requests.get(url,headers=headers)\n",
    "                soup = BeautifulSoup(response.text,'lxml')\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            t = soup.getText()\n",
    "            t = t.split('\"message\":')\n",
    "            t = t[2:len(t)]\n",
    "            for comment in t:      \n",
    "                comment = comment.split(',\"plat\"')[0]\n",
    "                comment  = text_clean(comment)\n",
    "                word_writer.writerow([comment,title, aid, link])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bullet Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><body><p>{\"code\":0,\"message\":\"0\",\"ttl\":1,\"data\":[{\"cid\":380318626,\"page\":1,\"from\":\"vupload\",\"part\":\"大碗牢饭_BiliBili\",\"duration\":111,\"vid\":\"\",\"weblink\":\"\",\"dimension\":{\"width\":1280,\"height\":720,\"rotate\":0}}]}</p></body></html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dm(df, num_vids):\n",
    "    f = codecs.open('bilibili_DanMu.csv','w','utf_8_sig')\n",
    "    word_writer = csv.writer(f)\n",
    "    word_writer.writerow([\"dm\",\"freq\",\"video_title\",\"video_id\",\"video_link\"])\n",
    "    for i in range(num_vids):\n",
    "        dic = {}\n",
    "        time.sleep(2)\n",
    "        aid = df.iloc[i].id\n",
    "        link = df.iloc[i].link\n",
    "        cid = conv(link)\n",
    "        title = df.iloc[i].title \n",
    "        add_dm(cid, dic)\n",
    "        sorted_d = sort_dic(dic)\n",
    "        counter = 0\n",
    "        for key in sorted_d:\n",
    "#         print(key,sorted_d[key])\n",
    "            counter += 1\n",
    "            word_writer.writerow([key,sorted_d[key],title,aid,link])\n",
    "        print(\"video: \", title ,\"finished. Added: \"+ str(counter) +\" unique DanMu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(link):\n",
    "    BV =link.split(\"/\")[2]\n",
    "    url = \"https://api.bilibili.com/x/player/pagelist?bvid=\"+ BV + \"&jsonp=jsonp\"\n",
    "    headers = { \n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'\n",
    "    } \n",
    "    try:\n",
    "        response = requests.get(url,headers=headers)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    dirt=json.loads(response.text)\n",
    "    cid=dirt['data'][0]['cid']\n",
    "    return cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dm(cid, dic):\n",
    "    url = \"https://api.bilibili.com/x/v1/dm/list.so?oid=\" + str(cid)\n",
    "    headers = { \n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'\n",
    "    } \n",
    "    try:\n",
    "        response = requests.get(url,headers=headers)\n",
    "        response.encoding =\"utf-8\"\n",
    "        soup = BeautifulSoup(response.text,'lxml')\n",
    "        dms = soup.findAll(\"d\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    # data=parse(response.text)\n",
    "    for dm in dms:\n",
    "        dm = dm.getText()\n",
    "        if (dm in dic):\n",
    "            dic[dm] = dic[dm]+1\n",
    "        else:\n",
    "            dic[dm] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dic(dic):\n",
    "    sorted_dict = {}\n",
    "    sorted_keys = sorted(dic, key=dic.get, reverse=True)  # [1, 3, 2]\n",
    "    for w in sorted_keys:\n",
    "        sorted_dict[w] = dic[w]\n",
    "    return sorted_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl():\n",
    "    inp = input('Enter number of videos(<50)：')\n",
    "    inp = int(inp)\n",
    "    rank_pop = \"https://www.bilibili.com/v/popular/rank/all\"\n",
    "    df = getAid(rank_pop)\n",
    "    get_dm(df,inp)\n",
    "    print(\"Finished dm!\")\n",
    "    getComments(df,inp)\n",
    "    print(\"Finished comments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
